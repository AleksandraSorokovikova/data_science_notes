{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание:\n",
    "\n",
    "1. [Обработка данных](#Обработка-данных)\n",
    "    1. [Предобработка](#Предобработка)\n",
    "    2. [Категоризация](#Категоризация)\n",
    "    3. [Устранение дубликатов](#Устранение-дубликатов)\n",
    "    4. [Стемминг](#Стемминг)\n",
    "    5. [Лемматизация](#Лемматизация)\n",
    "    6. [Заполнение пропусков](#Заполнение-пропусков)\n",
    "    7. [Удаление выбросов](#Удаление-выбросов)\n",
    "    8. [Разбиение выборки](#Разбиение-выборки)\n",
    "    9. [Приведение категориальных признаков к численным](#Приведение-категориальных-признаков-к-численным)\n",
    "    10. [Масштабирование количественных признаков](#Масштабирование-количественных-признаков)\n",
    "    11. [Снижение размерности или метод главных компонент PCA](#Снижение-размерности-или-метод-главных-компонент-PCA)\n",
    "    12. [Увеличение и уменьшение выборки upsampling и downsampling](#Увеличение-и-уменьшение-выборки-upsampling-и-downsampling)\n",
    "    13. [Bootstrapping](#Bootstrapping)\n",
    "    14. [Мешок слов](#Мешок-слов)\n",
    "    15. [Поиск стоп-слов](#Поиск-стоп-слов)\n",
    "2. [Метрики](#Метрики)\n",
    "    1. [Accuracy](#Accuracy)\n",
    "    2. [Precision](#Precision)\n",
    "    3. [Recall](#Recall)\n",
    "    4. [F1-мера](#F1-мера)\n",
    "    5. [AUC-ROC](#AUC-ROC)\n",
    "    6. [MSE](#MSE)\n",
    "    7. [RMSE](#RMSE)\n",
    "    8. [MAE](#MAE)\n",
    "    9. [R2](#R2)\n",
    "3. [Модели](#Модели)\n",
    "    1. [K-ближайших соседей](#K-ближайших-соседей)\n",
    "    2. [Наивный Байес](#Наивный-Байес)\n",
    "    3. [Линейная регрессия](#Линейная-регрессия)\n",
    "    4. [Логистическая регрессия](#Логистическая-регрессия)\n",
    "    5. [Деревья принятия решений](#Деревья-принятия-решений)\n",
    "    5. [Тематическое моделирование](#Тематическое-моделирование)\n",
    "    6. [Градиентный спуск](#Градиентный-спуск)\n",
    "    7. [Гребневая регрессия](#Гребневая-регрессия)\n",
    "    9. [Стохастический спуск](#Стохастический-спуск)\n",
    "    9. TODO\n",
    "4. [Статистика и теория вероятностей](#Статистика-и-теория-вероятностей)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных\n",
    "\n",
    "### Предобработка\n",
    "- Перевод строковых значений в числа: метод в **pandas** `to_numeric()`\n",
    "- Перевод строки в дату и время: метод в **pandas** `to_datetime()`\n",
    "- Приведение все к одному регистру: строковый метод `lower()`\n",
    "\n",
    "### Категоризация\n",
    "*Зачем*: в наборе данных некоторые категориальные значения (например, возраст) могут быть представлены только единожды, поэтому объединение их в группы облегчит дальнейшее изучение. \n",
    "\n",
    "*Вспомогательные методы:* метод в **pandas** `apply()` и `group()`\n",
    "\n",
    "### Устранение дубликатов\n",
    "*Зачем*: дубликаты в наблюдениях могут повлиять на интерпретацию результатов исследования, поэтому их можно удалять. \n",
    "\n",
    "*Вспомогательные методы:* метод в **pandas** `duplicated()` совместно с `sum()`, `value_counts()`\n",
    "\n",
    "### Стемминг\n",
    "*Зачем*: нужен при разделении строк по категориям. Стемминг находит *основу* слова (чтобы формы слова не повлияли на разделение по разным категориям)\n",
    "\n",
    "*Вспомогательные методы:* метод в **nltk.stem SnowballStemmer** `stem`\n",
    "\n",
    "### Лемматизация\n",
    "*Зачем*: затем же, зачем и стемминг. Лемматизация приводит слово к *словарной форме*(например, существительное к именительному падежу, глаголу к инфинитиву).\n",
    "\n",
    "*Вспомогательные методы:* метод в **pymystem3 Mystem** `lemmatize`, для подсчета количества вхождений **collections Counter**\n",
    "\n",
    "### Заполнение пропусков\n",
    "*Зачем*: поможет избежать большой потери данных, если пропусков слишком много, и улучшить качество модели. \n",
    "\n",
    "- заполнение пропусков по умолчанию. *Вспомогательные методы:* метод в **pandas** `fillna()`\n",
    "- заполнение количественных признаков характерными значениями: медиана (`median()`), среднее арифметическое (`mean()`) и тд.\n",
    "- посмотреть на распределение данных\n",
    "\n",
    "Если заполнение пропусков недопустимо, можно сбросить столбцы или строки с пропущенными значениями: метод в **pandas** `dropna()`\n",
    "\n",
    "### Удаление выбросов\n",
    "*Зачем*: в данных могут наблюдаться определенные закономерности (их можно увидеть с помощью ститистик и графиков), поэтому если в таких данных встречаются выбросы (например, указан 3014 год или у человека 40 детей), их необходимо удалять, чтобы они не влияли обучение.\n",
    "\n",
    "*Вспомогательные методы*: чтобы удалить выбросы, их сначала необходимо заметить. Для этого в следующих разделах будет показаны инструменты (построение графиков, вычисление статистик).\n",
    "\n",
    "### Разбиение выборки\n",
    "*Зачем*: чтобы лучше оценивать работоспособность модели, необходимо тестировать ее на данных, которые она раньше не видела.\n",
    "\n",
    "*Вспомогательные методы*: метод в **sklearn.model_selection** `train_test_split()`\n",
    "\n",
    "### Приведение категориальных признаков к численным\n",
    "*Зачем*: некоторые модели не работают с категориальными признаками (например, строками), для этого их необходимо преобразовать в численные.\n",
    "\n",
    "Методы:\n",
    "\n",
    "- ***Прямое кодирование (One-Hot-Encoding)***: под каждое значение категориального признака создается новый столбец, в котором ставится 1, если у наблюдения есть данный признак, 0 в противном случае. *Вспомогательные методы*: метод в **pandas** `get_dummies()`. Чтобы избежать *дамми-ловушки* (когда после добавления таких столбцов один из них становится лишним, так как в остальных и так достаточно информации; например, категория пол: для одного пола создается столбец принадлежности к данному полу, соответственно, столбец, где указана принадлежность к другому полу, не нужен, так как можно в первом указать, что данный человек не принадлежит первому полу). Для этого в методе `get_dummies()` используется аргумент `drop_first_True`\n",
    "- ***Порядковое кодирование (Ordinal-Encoding)***: присваивает каждому значению категориального признака номер и записывает их в новый столбец (например, в столбце \"Город\" есть три значения: Москва, Санкт-Петербург, Иркутск. Тогда после преобразования во всех строках, где город был \"Москва\", теперь будет стоять 0, где был \"Санкт-Петербург\", будет стоять 1 и так далее). *Вспомогательные методы*: метод в **sklearn.preprocessing OrdinalEncoder** `fit()` - для обучения на данных, `transform()` - для преобразования.\n",
    "\n",
    "### Масштабирование количественных признаков\n",
    "*Зачем*: модели могут быть чувствительны к разбросам значений (например, если мы поменяем размерность роста с сантиметров на дюймы), поэтому нужно их масштабировать. Для этого их можно стандартизировать (то есть привести среднее признака к 0, а дисперсию к 1). \n",
    "\n",
    "*Вспомогательные методы*: метод в **sklearn.preprocessing StandardScaler** `fit()` - для обучения и `transform()` - для преобразования.\n",
    "\n",
    "### Снижение размерности или метод главных компонент PCA\n",
    "*Зачем*: если в данных есть признаки, которые сильно коррелируют друг с другом, и нам необходимо снизить размерность, то есть слить эти признаки в один, можно применить PCA. Модель может переобучаться из-за переизбытка признаков, особенно если они сильно друг от друга зависят. В данном случае PCA может улучшить модель, а также лучше проиллюстрировать взаимосвязь в данных.\n",
    "\n",
    "*Вспомогательные методы*: метод в **sklearn.decomposition PCA** `fit_transform()` - это `fit()` и `transform()` в одном.\n",
    "\n",
    "### Увеличение и уменьшение выборки upsampling и downsampling\n",
    "*Зачем*: классы в данных могут быть не сбалансированы (например, в целевом признаке 90% будет занимать класс 0, и только остальные 10% класс 1). Поэтому можно увеличить количество наблюдений, в которых целевой признак находится в меньшинстве (в примере это класс 1), или наоборот уменьшить количество наблюдений, чей целевой признак находится в большинстве (класс 0). \n",
    "\n",
    "Для этого нужно разбить выборку (не тестовую) на классы, и случайным образом либо удалить наблюдения доминирующего класса, либо скопировать какое-то количество наблюдений дефицитного класса, и объединить с выборкой, после этого перемешать.\n",
    "\n",
    "*Вспомогательные методы*: метод в **pandas** `concat` для объединение выборок, `shuffle` - для перемешивания наблюдений\n",
    "\n",
    "### Bootstrapping\n",
    "*Зачем*: иногда может возникать такая ситуация, когда данные в выборке распределены так: около половины значений близки к 200, а половина к 0, тогда медиана может быть не очень показательной. Если бы имелась возможность неоднократно генерировать новые выборки, можно бы было вычислить медиану каждой и обратиться к распределению этих медиан. Если такой возможности нет, то можно обратиться к bootstrapping или методу рамножение выборок, когда из имеющихся выборок генерируют новые случайные выборки с возвратом размером n точек, а затем измеряют медианы этих выборок.\n",
    "\n",
    "https://github.com/joelgrus/data-science-from-scratch/blob/master/scratch/multiple_regression.py\n",
    "\n",
    "TODO: вставить ссылку получше\n",
    "\n",
    "### Мешок слов\n",
    "*Зачем*: нужен для подготовки к машинному обучению текстов (то есть естественного языка). Мешок слов преобразует текст в вектор, не учитывая порядок слов.\n",
    "\n",
    "*Вспомогательные методы*: метод в `sklearn.feature_extraction.text CountVectorizer`\n",
    "\n",
    "### Поиск стоп-слов\n",
    "*Зачем*: нужен для подготовки к машинному обучению текстов (то есть естественного языка). Некоторые слова в тексте не несут никакого смысла (например, союзы или предлоги), поэтому от них нужно избавляться.\n",
    "\n",
    "*Вспомогательные методы*: метод в `nltk.corpus stopwords`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Метрики\n",
    "\n",
    "### Accuracy\n",
    "Измеряет долю правильных ответов, то есть $$accuracy = \\frac{N_{true}}{N_{all}}$$ где $N_{true}$ - количество правильных ответов, $N_{all}$ - количество всех ответов.\n",
    "\n",
    "***Референтные значения***: чем ближе метрика к 1, тем лучше модель; чем ближе метрика к 0, тем модель хуже.\n",
    "\n",
    "***Где применяется***: задача *классификации*. Однако если целевые классы несбалансированы, **accuracy** может быть завышена.\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `accuracy()`\n",
    "\n",
    "### Precision\n",
    "Определяет, как много отрицательных ответов нашла модель, пока искала положительные. Чем больше отрицательных, тем ниже точность.\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "где $TP$ - истинноположительные ответы, $FP$ - ложноположительные ответы. \n",
    "\n",
    "***Референтные значения***: чем ближе метрика к 1, тем лучше модель; чем ближе метрика к 0, тем модель хуже.\n",
    "\n",
    "***Где применяется***: задача *классификации*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `precision_score()`\n",
    "\n",
    "### Recall\n",
    "Определяет какую долю положительных среди всех ответов выделила модель. Если значение **recall** близко к единице, то модель хорошо ищет положительные объекты.\n",
    "\n",
    "$$recall = \\frac{TP}{TP+FN}$$\n",
    "где $TP$ - истинноположительные ответы, $FN$ - ложноотрицательные ответы. \n",
    "\n",
    "***Референтные значения***: чем ближе метрика к 1, тем лучше модель; чем ближе метрика к 0, тем модель хуже.\n",
    "\n",
    "***Где применяется***: задача *классификации*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `recall_score()`\n",
    "\n",
    "### F1-мера\n",
    "Данная метрика объединяет **precision** и **recall**, она является гароническим средним между ними:\n",
    "$$f1 = \\frac{2*precision*recall}{precision+recall}$$\n",
    "\n",
    "***Референтные значения***: чем ближе метрика к 1, тем лучше модель; чем ближе метрика к 0, тем модель хуже.\n",
    "\n",
    "***Где применяется***: задача *классификации*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `f1_score`\n",
    "\n",
    "### AUC-ROC\n",
    "**ROC-кривая** показывается соотношение *TPR* и *FPR* - доля истинноположительных ответов и доля ложноположительных ответов. Чем выше данная кривая, тем лучше модель. ROC-кривая для случайной модели можно представить в виде прямой $y=x$. Соответственно, если кривая модели выше случайной, то она предсказывают лучше, чем случайная. **AUC-ROC** (area under curve roc) - это площадь под ROC-кривой.\n",
    "\n",
    "***Референтные значения***: чем ближе метрика к 1, тем лучше модель; чем ближе метрика к 0, тем модель хуже. \n",
    "\n",
    "***Где применяется***: задача *классификации*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `roc_auc_score`\n",
    "\n",
    "В отличие от других метрик, данная метрика принимает в качестве аргумента вероятности класса 1, а не предсказаения модели.\n",
    "\n",
    "### MSE\n",
    "Определяет среднеквадратичную ошибку (mean squared error).\n",
    "$$MSE = \\frac{1}{N}\\sum^{N}_{i=1}(y_i-Y_i)^2$$\n",
    "где $N$ - количество наблюдений, $y_i$ - предсказание модели, $Y_i$ - правильный ответ\n",
    "\n",
    "***Референтные значения***: чем меньше метрика, тем лучше\n",
    "\n",
    "***Где применяется***: задача *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `mean_squared_error`\n",
    "\n",
    "### RMSE\n",
    "Определяет корень от среднеквадратичной ошибки.\n",
    "$$RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "***Референтные значения***: чем меньше метрика, тем лучше\n",
    "\n",
    "***Где применяется***: задача *регрессии*\n",
    "\n",
    "### MAE\n",
    "Определяет среднее абсолютное расстояние между прогнозируемыми и целевыми значениями. Данная метрика более устойчива к выбросам, чем **MSE**, а также является менее чувствительной к большим значениям, нежели **RMSE** \n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum^{N}_{i=1}|y_i-Y_i|$$\n",
    "где $N$ - количество наблюдений, $y_i$ - предсказание модели, $Y_i$ - правильный ответ\n",
    "\n",
    "***Референтные значения***: чем меньше метрика, тем лучше\n",
    "\n",
    "***Где применяется***: задача *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `mean_absolute_error`\n",
    "\n",
    "\n",
    "### R2\n",
    "\n",
    "Коэффициент детерминации. Измеряет долю суммарной вариации в зависимой переменной. \n",
    "\n",
    "$$R2 = 1 - \\frac{MSE_{model}}{MSE_{mean}}$$\n",
    "где $MSE_{model}$ - MSE модели, $MSE_{mean}$ - MSE среднего\n",
    "\n",
    "***Референтные значения***: Чем ближе значение $R2$ к единице, тем лучше предсказывает модель. Если $R2 = 0$, то модель работает так же, как случайная. Если $R2<0$, то модель предсказывает хуже, чем случайная.\n",
    "\n",
    "***Где применяется***: задача *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: метод в **sklearn.metrics** `r2_score`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-ближайших соседей\n",
    "\n",
    "Данная модель является простейшей. Для ее использования необходимо:\n",
    "\n",
    "- некоторое представление о расстоянии\n",
    "- предположение, что точки, близко расположенные друг к другу, подобны\n",
    "\n",
    "Данные должны быть представлены в виде векторов, где каждое значение является числом. Алгоритм следующий:\n",
    "\n",
    "- Вычислить расстояние до каждого из объектов обучающей выборки\n",
    "- Отобрать k объектов обучающей выборки, расстояние до которых минимально\n",
    "- Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей\n",
    "\n",
    "***Где применяется***: задача *классификации* и *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: https://scikit-learn.org/stable/modules/neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Наивный Байес\n",
    "\n",
    "##### Теорема Байеса\n",
    "\n",
    "События $A_1, ..., A_k$ образуют полную группу (то есть $P(A_1) + ... + P(A_k) = 1$).\n",
    "\n",
    "Тогда $P(B)$ - полная вероятность события $B$:\n",
    "$$P(B) = P(A_1)*P(B|A_1) + ... + P(A_k)*P(B|A_k)$$\n",
    "\n",
    "Вероятность наступления события $A_i$ при условии, что $B$ произошла **по теореме Байеса** равна:\n",
    "$$P(A_i|B) = \\frac{P(B|A_i)*P(A_i)}{P(B)}$$\n",
    "\n",
    "##### Сглаживание\n",
    "\n",
    "Например, если мы создаем спам-фильтр, и статистика указывает на то, что слово *A* содержится только в неспамных письмах, то при применении данной теоремы для фильтрации писем все сообщения, которые содержат данное слово, будут являться неспамными (что может быть неверное), так как $P(A|S) = 0$.\n",
    "\n",
    "Чтобы это избежать, мы можем подобрать такую константу $k$, чтобы *сгладить* подобные выборсы:\n",
    "$$P(X_i|S) = \\frac{k+N_{x_i}}{2k+N}$$\n",
    "где $N_{x_i}$ - число спамных сообщений, содержащих слово $x_i$, $N$ - число спамных сообщений\n",
    "\n",
    "##### Как работает теорема Байеса в спам-фильтре\n",
    "В основе классификатора лежит допущение о том, что наличие (или отсутствие) того или иного слова не зависит от других слов в спамном или неспамном сообщении. Это допущение позволяет вычислить итоговую вероятность, просто перемножив между собой индивидуальные вероятностные оценки для каждого слова. На практике обходятся без перемножения, переходя к сложения логарифмов.\n",
    "\n",
    "\n",
    "##### Применение\n",
    "\n",
    "С помощью данной модели мы можем *классифицировать* признаки на разные группы, вычислив вероятность их попадания в тот или иной класс.\n",
    "\n",
    "\n",
    "***Где применяется***: задача *классификации* \n",
    "\n",
    "***Вспомогательные методы***: https://scikit-learn.org/stable/modules/naive_bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Линейная регрессия\n",
    "\n",
    "Данная модель применяется, если есть основания полагать, что между признаками и целевым признаком существует линейная связь (например, подсчитав корреляцию).\n",
    "\n",
    "Если представить, что признак, который мы ищем ($y_i$), линейно зависит от данного признака (x_i), то мы можем найти такие коэффициенты $\\alpha$ и $\\beta$, что:\n",
    "$$y_i = \\alpha * x_i + \\beta + \\epsilon$$\n",
    "где $\\epsilon$ какая-то незначительная ошибка. Тогда найдя коэффициенты при обучении модели, можем спронозировать ответы для будущих признаков. Если есть несколько независимых признаков, по которым нужно предсказать целевой признак, то можем применить множественную линейную регрессию, то есть необходимо найти такие коэффициенты $\\beta_1, ..., \\beta_n$, что \n",
    "$$y_i = \\alpha + \\beta_1*x_1 + ... \\beta_n*x_n + \\epsilon$$\n",
    "где $(x_1, ..., x_n)$ - вектор признаков.\n",
    "\n",
    "Чтобы применить модель множественной линеной регрессии, вектора признаков должны быть ЛНЗ.\n",
    "\n",
    "Подбор модели осуществляется путем минимизации суммы квадратов случайных ошибок, после чего выбирается параметр $\\beta$, который максимизирует правдоподобие данных\n",
    " \n",
    "\n",
    "***Где применяется***: задача *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Логистическая регрессия\n",
    "\n",
    "Если дана задача классификации, то есть нужно отнести данные к классу 0, либо к классу 1, модель линейной регрессии может выдавать результаты, которые сложно интерпретировать (например, огромные числа, иногда отрицательные). Также есть допущение, что при применении линейной регрессии данные не должно коррелировать, на деле это не всегда так.\n",
    "\n",
    "В моделе логистической регрессии используется логистическая функция, которая считает *вероятности* попадания в тот или иной класс:\n",
    "$$L = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "Соответственно, если входящие значения увеличиваются и > 0, то результат функции стремится к 1. Если значения увеличиваются и < 0, то функция стремится к 0. Затем ставится определенный порог (например, 0.5), и значения разносятся по классам.\n",
    "\n",
    "Для подбора модели используется функция максимального правдоподобия (точнее, ее логарифм), ее нужно максимизировать: \n",
    "$$\\ln L(\\beta |x_i, y_i) = y_i\\ln f(x_i\\beta) +(1-y_i)\\ln (1-f(x_i \\beta))$$\n",
    "\n",
    "***Где применяется***: задача *классификации*\n",
    "\n",
    "***Вспомогательные методы***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Деревья принятия решений\n",
    "\n",
    "Деревья отличаются от других моделей тем, что результат легко интерпретировать. Также, они легко справляются как с численными признаками, так и с качественными. Однако задача нахождения оптимального дерева является вычислительно сложной. Второй минус заключается в том, что деревья слишком *подогнаны* под обучающую выборку и плохо обобщают не встречавшиеся ранее данные. Деревья подразделяются на *классификационные* и на *регрессионные*. \n",
    "\n",
    "Для подбора подходящей модели считается *энтропия*. Пусть есть набор данных $S$, где каждый элемент принадлежит одному из классов $C_1, ..., C_n$. Если все точки принадлежат одному классу, то энтропия почти отсутствует. Если все точки равномерное распределенны между классами, то уровень энтропии высокий.\n",
    "\n",
    "Энтропия определяется следующей формулой:\n",
    "$$H(S) = -p_1\\log p1 - ... - p_n\\log p_n$$\n",
    "где $p_i$ - пропорция данных, принадлежащая классу $c_i$. Каждый член $p_i\\log p_i$ принимает неотрицательное значение, близкое к 0, когда $p_i$ близок к 0 или 1.\n",
    "\n",
    "Далее нам необходимо разделять выборку посредством уточняющий вопросов. Если данные расщепляются на подгруппы, которые обладают низкой энтропией (неопределенностью), то энтропия итогового распределения должна быть низкой, и, соответственно, наоборот. Например, при поиске загаданного животного, вопрос \"присутствует ли это животное на австралийской монете\" разделил животных на подгруппы $S_1$ = {ехидна} и $S_2$ = {все остальные}. $S_1$ обладает нулевой энтропией, так как нет неопределенности, но $S_2$ обладает высокой энтропией.\n",
    "\n",
    "Энтропия разбиения является взвешенной суммой:\n",
    "$$H = q_1H(S_1) + ... + q_mH(S_m)$$\n",
    "где $q_i$ - пропорции данных, $S_i$ - подгруппы.\n",
    "\n",
    "***Важное замечание:***\n",
    "\n",
    "> расщепление признаков с большим количеством значений приведет к очень низкой энтропии из-за переобучения. Например, если банк анализирует своих клиентов на предмет погашения долга, и среди прочих в признаках есть номер социального страхования, то расщепление данных по этому признаку приведет к генерации подмножеств, которые состоят из одного человека, то есть подмножетсва будут обладать нулевой энтропией. Однако такая модель не сможет обобщать за пределами обучающей выборки, а потому будет переобучена\n",
    "\n",
    "Поэтому **нужно избегать признаки с большим числом возможных значений**\n",
    "\n",
    "Модель состоит из решающих узлов (содержат вопрос) и листовых узлов (делают прогноз).\n",
    "\n",
    "Вот пример алгоритма для построения решающего дерева, который называется **ID3**:\n",
    "1. Если все данные имеют одинаковую метку (то есть целевой признак), то создать листовой узел, который предсказывает эту метку\n",
    "2. Если список признаков пуст (то есть больше нет вопросов), то создать листовой узел, который предсказывает наиболее общую метку, и остановиться\n",
    "3. В противном случае пытаться разбить данные по каждому признаку\n",
    "4. Выбрать разбиение с наименьшей энтропией\n",
    "5. Добавить решающий узел на основе выбранного признака\n",
    "6. Рекурсивно повторить для каждой подгруппы, получившейся в результате разбиения, использую оставшиеся признаки\n",
    "\n",
    "Данный алгоритм является *жадным*, то есть он строит по оптимальным шагам, но итоговое дерево может получиться не оптимальным.\n",
    "\n",
    "Еще некоторые алгоритмы построения решающего дерева:\n",
    "1. ID3\n",
    "2. C4.5\n",
    "3. CART\n",
    "и т.д.\n",
    "\n",
    "Чтобы избежать тенденцию к переобучению у решающих деревьев, используется ***случайный лес*** - этот алгоритм создает несколько решающих деревьев, которые затем принимают коллективное итоговое решение.\n",
    "\n",
    "**Как именно сделать так, чтобы деревья были различные?**\n",
    "1. Можно применить bootstrap-метод. Вместо того, чтобы обучать деревья на всем наборе данных, их обучают на результате вызова функции, которая генерирует bootstrap-выборки. \n",
    "2. Можно изменить способ выбора наилучшего признака, по которому выполняется расщепление. Например, сначала выбрать случайное подмножество, а затем расщеплять по наилучшему из них.\n",
    "\n",
    "\n",
    "***Где применяется***: задача *классификации* и *регрессии*\n",
    "\n",
    "***Вспомогательные методы***: \n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Кластеризация\n",
    "\n",
    "Кластеризация нужна тогда, когда у нас нет целевого признака. Это называется обучение без учителя. Допустим, есть набор данных, и необходимо его сгруппировать наиболее оптимальным образом. Так как нельзя посчитать *отклонение*, используя целевой признак, нужно подобрать целевую функцию. В большинстве задач кластеризации измеряется расстояние между объектами.\n",
    "\n",
    "Одним из простейших методов кластеризации является *метод k-средних*, число k выбирается заранее. Задача состоит в том, чтобы сегментировать входящие значения на подмножетсва $S_1, ..., S_k$ таким образом, чтобы минимизировать полную сумму квадратов расстояний от каждой точки до среднего значения назначенного ей кластера.\n",
    "\n",
    "Итеративный алгоритм:\n",
    "1. Каждому объекту случайным образом присовить номер кластера от 1 до k\n",
    "\n",
    "\n",
    "2. Пока кластеры объектов не перестанут меняться:\n",
    "\n",
    "    i. вычислим центроид каждого кластера\n",
    "    \n",
    "    ii. каждому объекту присвоим номер нового кластера, центроид которого расположен ближе всего к объекту\n",
    "    \n",
    "Значение центроида вычисляется как среднее значение векторов:\n",
    "$$C = \\frac{1}{N} (\\sum^N_{j=1}x_1^j, \\sum^N_{j=1}x_2^j, ..., \\sum^N_{j=1}x_n^j)$$\n",
    "\n",
    "***Метод локтя для поиска оптимального числа кластеров***\n",
    "\n",
    "Чтобы определить оптимальное k, нужно построить график целевой функции (для k-means это сумма внутрикластерных расстояний) при различных k, и смотреть, в какой точке график уходит в плато.\n",
    "\n",
    "\n",
    "**Восходящий метод иерархической кластеризации**\n",
    "\n",
    "Смысл алгоритма состоит в том, чтобы постепенно объединять ближайшие друг к другу точки, пока не останется один кластер:\n",
    "1. Сделать каждое входящее значение одноточечным кластером (из одного элемента).\n",
    "2. Пока остается больше одного кластера, найти два ближайших и объединить\n",
    "\n",
    "В итоге получится один кластер для всех точек. Если отслеживать порядок объединения, можно воссоздать любое число кластеров путем их разъединения.\n",
    "\n",
    "Целевую функцию можно менять. Функция **min** порождает цепеобразные кластеры, функция **max** - более плотные кластеры.\n",
    "\n",
    "Вычисление расстояния каждый раз является неэффективным. В более эффективных реализациях все попарные расстояния считаются заранее, а затем выполняется поиск внутри списка расстояний. Также можно учитывать расстояния предыдущего шага.\n",
    "\n",
    "\n",
    "***Где применяется***: задача *кластеризации*\n",
    "\n",
    "***Вспомогательные методы***: https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Тематическое моделирование\n",
    "\n",
    "Данная модел используется для определения общих тематик в текстах. То есть, например, когда дан массив документов, состоящих из списка слов, и необходимо определеить распределение тем по документам и распределение слов по темам (то есть определить, какие темы встречаются в документах и какие слова принадлежат той или иной теме).\n",
    "\n",
    "Для начала рассмотрим ***метод сэмплирование по Гиббсу***:\n",
    "\n",
    "**Пример:** пусть нам даны два игральных кубика, и необходимо сгенерировать выборку из пар *(x, y)*, где *x* - значение первого кубика, *y* - сумма значений первого и второго кубиков. \n",
    "\n",
    "***Сэмплирование по Гиббсону*** - это метод извлечение выборок из многомерных распределений, когда известны лишь некоторые условные распределения.\n",
    "\n",
    "Метод работает так: начинаем с любого допустимого значения x и y, и затем многократно чередуем, подставляя вместо x случайное значение, выбранное в зависимости от y, и вместо y - случайное значение, выбранное в зависимости от x. После ряда итераций полученные значения будут представлять выборку из безусловного совместного распределения.\n",
    "\n",
    "\n",
    "***Переходим к модели:***\n",
    "\n",
    "Для определения общих тематик в тексте используется метод ***латентного размещения Дирихле (latent Dirichlet allocation)***, которая предполагает следующие аспекты:\n",
    "\n",
    "- имеется постоянное число **K** общих тематик\n",
    "- имеется случайная величина, которая каждой тематике ставит в соответствие распределение вероятностей на множестве слов (вероятность наблюдать слово *w* в заданной тематике *k*)\n",
    "- имеется случайная величина, которая каждому документу назначает распределение вероятностей на множестве тематик (смесь тематик в документе *d*)\n",
    "- каждое слово в документе генерируется путем случайноого выбора тематик (из распределения тематик для данного документа), а затем случайного выбора слова (из распределения слов в заданной тематике)\n",
    "\n",
    "***Алгоритм:***\n",
    "\n",
    "Случайно назначим тематики всем словам, далее пройдемся по каждому слову. По слову и документу сконструируем веса для каждой тематики, затем применим веса для выборки новой тематики, соответствующей этому слову. После многочисленных итерация получим выборку из распределения \"тематика-слово\" и \"документ-тематика\". \n",
    "\n",
    "> Можно оценить правдоподобие того, что тематика 1 служит причиной для появления определенного слова, сравнивая частотность, с которой тематика 1 производит это слово, с частотностью, которой она производит *любое* слово\n",
    "\n",
    "Тематики представлены числами, однако их можно характеризовав словом, которое имеет *наибольший вес* в данной тематике.\n",
    "\n",
    "> Правдоподобие выбора тематики зависит одновременно оттого, насколько правдоподобна эта тематика для документа и насколько правдоподобно это слово для этой тематики.\n",
    "\n",
    "***Где применяется***: задача *кластеризации*\n",
    "\n",
    "***Вспомогательные методы***: \n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "2. https://radimrehurek.com/gensim/\n",
    "\n",
    "\n",
    "### TF-IDF\n",
    "Оценка важности слова определяется величиной TF-IDF. То есть TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе.\n",
    "\n",
    "$$TF-IDF = TF*IDF$$\n",
    "\n",
    "$$TF = \\frac{t}{n}$$\n",
    "где $t$ - количество употребления слова, $n$ - общее число слов в тексте. IDF нужна в формуле, чтобы уменьшить вес слова, которое наиболее сильно распространено в любом другом тексте заданного корпуса. \n",
    "$$IDF=\\log_{10} (\\frac{D}{d})$$\n",
    "где $D$ - общее число текстов в корпусе, &d& - количество текстов, в которых встречается это слово.\n",
    "\n",
    "Большая величина TFIDF говорит об уникальности слова в тексте по отношению к корпусу. Чем чаще оно встречается в конкретном тексте и реже в остальных, тем выше значение TFIDF.\n",
    "\n",
    "***Вспомогательные методы***: метод в `sklearn.feature_extraction.text TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск используют для минимизации функции ошибки (**loss function**), чтобы подобрать наиболее подходящие параметры. Сам алгоритм работает так: \n",
    "1. Выбирается начальная точка\n",
    "2. Вычисляется градиент функции (направление наибольшего роста функции или вектор частных производных по всем аргументам) и вычитается из текущего значения аргумента (при этом градиент домножается на **learning rate** $\\alpha$:\n",
    "$$x_i = x_{i-1} - \\alpha\\cdot \\nabla f(x)_{i-1}$$\n",
    "3. Шаги повторяем до тех пор, пока изменения функции не будут достаточно маленькими или не пройдем много шагов (заранее заданное число).\n",
    "\n",
    "У данного подхода есть минусы:\n",
    "1. Градиентный спуск ищет локальный минимум. Алгоритм может завершиться, даже если глобальный минимум другой\n",
    "2. Мы можем пропустить минимум, делая слишком большие шаги. А делая слишком маленькие шаги, обучение будет длиться слишком долго\n",
    "3. Градиент вычисляется на каждом шаге на всем наборе данных\n",
    "4. Функция должна быть непрерывной (даже гладкой)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаг градиента\n",
    "def gradient_step(v, gradient, step_size):\n",
    "    return [v_i + step_size*gradient_i \n",
    "            for  v_i, gradient_i in zip(v, gradient)]\n",
    "\n",
    "# градиентный спуск для нахождения вектора theta, который минимизирует целевую функцию (функцию ошибок) target_function\n",
    "def gradient_descent(target_function, gradient_function, x_0, threshold = 0.000001):\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    x = x_0\n",
    "    minimized_value = target_function(x)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        gradient = gradient_function(x)\n",
    "        \n",
    "        next_x_vector = [gradient_step(x, gradient, -step_size) for step_size in step_sizes]\n",
    "        \n",
    "        next_x = min(next_x_vector, key=target_function)\n",
    "        next_minimized_value = target_function(next_x)\n",
    "        \n",
    "        if abs(minimized_value - next_minimized_value) < threshold:\n",
    "            return x\n",
    "        else:\n",
    "            x = next_x\n",
    "            minimized_value = next_minimized_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Пример нахождения минимума функции $f(x, y) = (x-1)^2 + y^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимум функции f(x) = (x-1)^2 + y^2 достигается в точке (1.0, 0.0) и равен 0.0\n"
     ]
    }
   ],
   "source": [
    "def target_function(x):\n",
    "    return (x[0]-1)**2 + x[1]**2\n",
    "\n",
    "def gradient_function(x):\n",
    "    return [(x[0]-1)*2, x[1]*2]\n",
    "\n",
    "# веса нужно подбирать случайно\n",
    "x_0 = [10, 10]\n",
    "minimum = gradient_descent(target_function, gradient_function, x_0)\n",
    "print(\"Минимум функции f(x) = (x-1)^2 + y^2 достигается в точке ({0:.1f}, {1:.1f}) и равен {2:.1f}\".format(minimum[0], \n",
    "                                                                                         minimum[1], \n",
    "                                                                                         target_function(minimum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стохастический градиентный спуск, в отличие от обычного, на каждой итерации вычисляет градиент и делает шаг только в одной точке. Он многократно просматривает данные, пока не достигнет точки останова. Этот алгоритм работает, так как функции потерь имеют свойство аддитивности (то есть прогнозная ошибка на всем наборе данных является суммой прогнозных ошибок для каждой точки данных). Во время каждого цикла просмотр данных выполняется в случайном порядке, шаг градиента делается для каждой точки.\n",
    "\n",
    "То есть вместо вычисления градиента по всей выборке, градиент вычисляется на одном случайном объекте, и веса подбираются так, чтобы уменьшить ошибку только на нем. Алгоритм останавливается тогда, когда на последних $n$ шагах значение функции не менялось.\n",
    "\n",
    "Проблема SGD закллючается в том, что в окрестности минимума он начинает прыгать и может зависнуть или не найти минимум. Это решается с помощью постепенного уменьшения шага (**learning rate**). \n",
    "\n",
    "Пример подбора `learning rate` на каждом шаге `t`: $\\eta = \\frac{0.1}{t^{0.3}}$\n",
    "\n",
    "### Mini-batch\n",
    "Идея та же, что и в стохастическом градиентом спуске, только вместо одного случайного объекта, на котором оценивается градиент функции ошибки, берется *случайная выборка* таких объектов. Размер выборки подбирается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# (xy) это пара (training_set, target)\n",
    "def stochastic_gradient_descent(max_epochs,threshold,w_init,\n",
    "                                obj_func,grad_func,xy,\n",
    "                                learning_rate=0.05,momentum=0.8):\n",
    "    (x_train,y_train) = xy\n",
    "    w = w_init\n",
    "    w_history = w\n",
    "    f_history = obj_func(w,xy)\n",
    "    delta_w = np.zeros(w.shape)\n",
    "    i = 0\n",
    "    diff = 1.0e10\n",
    "    rows = x_train.shape[0]\n",
    "    \n",
    "    while  ithreshold:\n",
    "        np.random.seed(i)\n",
    "        p = np.random.permutation(rows)\n",
    "\n",
    "        for x,y in zip(x_train[p,:],y_train[p]):\n",
    "            delta_w = -learning_rate*grad_func(w,(np.array([x]),y)) + momentum*delta_w\n",
    "            w = w+delta_w\n",
    "            \n",
    "        i+=1\n",
    "        w_history = np.vstack((w_history,w))\n",
    "        f_history = np.vstack((f_history,obj_func(w,xy)))\n",
    "        diff = np.absolute(f_history[-1]-f_history[-2])\n",
    "        \n",
    "    return w_history, f_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Временные ряды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO (еще много моделей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистика и теория вероятностей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Биномиальное распределение\n",
    "\n",
    "(сказать про оценку вероятности гипотез с помощью биномиального распределения)\n",
    "\n",
    "### Бета-распределение\n",
    "Бета-распределение нужно тогда, когда у нас нет вероятности, однако есть данные, чтобы эту вероятность получить (например, нам дан черный ящик, который может выдать, а может и не выдать монетку). Исходно мы не знаем вероятности, однако мы можем получить данные (провести много экспериментов) и узнать примерную вероятность (точнее, получить вероятность того, что вероятность нужного нам явления равна такому-то числу). \n",
    "> Бета-распределение описывает, насколько мы уверены в каждой из возможных гипотез об имеющихся данных\n",
    "\n",
    "Бета-распределение определено на сплошном интервале. Определим бета-распределение через плотность вероятности (probability\n",
    "density function, PDF):\n",
    "$$Beta(p; \\alpha, \\beta) = \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{beta(\\alpha, \\beta)}$$\n",
    "\n",
    "где:\n",
    "\n",
    "- $p$ обозначает вероятность события\n",
    "- $\\alpha$ показывает, сколько раз произошло интересующее нас событие, например получение двух монет.\n",
    "- $\\beta$ — сколько раз оно не произошло \n",
    "- Общее число испытаний равно α + β\n",
    "- Бета-функция ($beta(\\alpha, \\beta)$) - это интеграл от 0 до 1 от $p^{\\alpha –1}(1 – p)^{\\beta – 1}$\n",
    "> К бета-распределению мы пришли, сравнив, насколько хорошо разные биномиальные распределения, каждое со своей собственной вероятностью p, описывают наши данные. Другими словами, бета-распределение показывает, насколько хорошо все возможные биномиальные распределения описывают наблюдаемые данные.\n",
    "\n",
    "**Среднее значение Beta-распределения $\\mu$:**\n",
    "$$\\mu_{Beta} = \\frac{\\alpha}{\\alpha+\\beta}$$\n",
    "\n",
    "\n",
    "### Апостериорная вероятность\n",
    "Пусть $H$ - гипотеза (предположение), $D$ - какие-то данные\n",
    "\n",
    "**Апостериорная вероятность** - это правдивость предположения (гипотезы $H$) на основе имеющихся у нас данных ($D$): $P(H|D)$\n",
    "\n",
    "**Априорная вероятность** - это вероятность того, что гипотеза $H$ правдива: $P(H)$\n",
    "\n",
    "**Правдоподобие** - это вероятность имеющихся данных ($D$) при условии наших предположений (гипотезы $H$): $P(D|H))$\n",
    "\n",
    "Тогда по теореме Байеса:\n",
    "$$P(H|D)=\\frac{P(D|H)P(H)}{P(D)}$$\n",
    "\n",
    "> Данной формулой мы можем воспользоваться для сравнения двух гипотез (нулевой и альтернативной), чтобы выяснить, какая гипотеза наиболее вроятна. Так как мы смотрим на отношение, то $P(D)$ сокрщается.\n",
    "\n",
    "Для сравнения гипотез можно пользоваться другой формулировкой теоремы Байеса:\n",
    "$$P(H|D) \\sim P(H)\\times P(D|H)$$\n",
    "которая говорит о том, что *апостериорная вероятность — вероятность гипотезы при условии данных — пропорциональна априорной вероятности H, умноженной на вероятность данных при условии H*\n",
    "\n",
    "### Математическое ожидание\n",
    "Это сумма каждого значения, взвешенного по его вероятности, или среднеожидаемое значение при многократном повторении испытаний:\n",
    "$$\\mu = \\sum_1^n p_ix_i$$\n",
    "где $x_i$ -  случайная величина, $p_i$ - вероятность данной случайной величины.\n",
    "> математическим ожиданием можно описать, например, средний выигрыш в лотерею или количество инверсий на всех перестановках чисел от 1 до n.\n",
    "\n",
    "> Если эксперимент состоит из равновероятных элементарных исходов, заданных численно, математическое ожидание будет равно среднему возможных значений.\n",
    "\n",
    "### Медиана\n",
    "Медиана - это точка в данных, в которой половина значений приходится на одну сторону, а половина на другую. Другими словами, вероятность того, что значение больше медианы, и вероятность того, что оно меньше медианы, равна 0,5. Чтобы найти медиану в выборке дискретных величин, их нужно упорядочить по возрастанию и взять серединный элемент (если элементов четное количество, то взять среднее арифметическое двух средних элементов выборки).\n",
    "\n",
    "Вычислить медиану непрерывной случайно величины можно воспользовавшись функцией CDF (функция накопленной плотности), например, посмотрев на ее график. В значении, где совокупная вероятность равна 0.5, там и будет медианное значение выборки.\n",
    "\n",
    "### Среднее абсолютное отклонение\n",
    "Когда нам необходимо измерить разброс данных, мы можем использовать *cреднее абсолютное отклонение* - оно складывает модули разности между средним значением выборки и каждого значения:\n",
    "$$MAD(x) = \\frac{1}{n} \\sum_1^n |x_i-\\mu| $$\n",
    "где $x_i$ - значение случайной величины, $\\mu$ - среднее выборки (или мат ожидание). Деление на $n$ дает независимость от размера выборки.\n",
    "\n",
    "### Дисперсия\n",
    "Дисперсия характеризует разброс случайной величины вокрус ее математического ожидания. Дисперсия похожа на cреднее абсолютное отклонение, однако она *более чувствительна к отклонениям от среднего (мат ожиданию)*, так как вместо модуля используется квадрат:\n",
    "$$Var(x) = \\frac{1}{n} \\sum_1^n (x_i-\\mu)^2 $$\n",
    "Более формально: возведение в квадрат приводит к *экспоненциальному штрафу*. \n",
    "\n",
    "### Стандартное отклонение\n",
    "Стандартное отклонение равно корню из дисперсии:\n",
    "$$\\sigma = \\sqrt{Var(x)} = \\sqrt{\\frac{1}{n} \\sum_1^n (x_i-\\mu)^2}$$\n",
    "Стандартное отклонение также используется для измерения разброса случайной величины, однако оно более интуитивно понятно, чем дисперсия, так как единицы измерения не квадрат исходной величины, а единица измерения самой величины.\n",
    "> Для большинства распределений верно правило трёх стандартных отклонений, или правило трёх сигм. Оно гласит — практически все значения (около 99% находятся в промежутке): $(\\mu − 3\\sigma, \\mu + 3\\sigma)$, где $\\mu$ - среднее (или мат ожидание), $\\sigma$ - стандартное отклонение. Это правило позволяет не только находить интервал, в который наверняка попадут практически все значения интересующей нас переменной, но и искать значения вне этого интервала (выборсы).\n",
    "\n",
    "### Нормальное распределение\n",
    "Нормальное распределение — это непрерывное распределение вероятностей, которое наилучшим образом описывает силу возможных убеждений в значении неопределенного измерения, учитывая известное среднее значение и стандартное отклонение. Оно принимает значения $\\mu$ (среднее или мат ожидание) и $\\sigma$ (стандартное отклонение) в качестве двух параметров. Центр нормального распределения — это среднее значение. Ширина нормального распределения определяется его стандартным отклонением.\n",
    "> Когда единственное, что мы знаем о проблеме, — это среднее значение и стандартное отклонение наблюдаемых данных, то нормальное распределение является наиболее достоверным представлением состояния убеждений.\n",
    "\n",
    "С помощью нормального распределения мы можем получить следующие значения:\n",
    "\n",
    "- **Функция плотности вероятности (PDF)** - возвращает вероятность для известного наблюдения, имеющего конкретное значение из распределения (то есть если нам дано наблюдение и нужно выяснить, какова вероятность того, что данное наблюдение попадет в наше распределение).\n",
    "- **Функция накопленной плотности (CDF)** - возвращает вероятность для известного наблюдения, равную или меньшую, чем конкретное значение из распределения (то есть если нам дано наблюдение, функция возвращает вероятность интервала слева или справа).\n",
    "- **Функция точки процента (PPF)** - возвращает значение наблюдения для известной вероятности, которое меньше или равно предоставленной вероятности из распределения (то есть если нам дана вероятность, по которой нужно определить, какое значение попадает под эту вероятность в распределении слева или справа).\n",
    "\n",
    "PDF для нормального распределения такая:\n",
    "$$N(\\mu, \\sigma) = \\frac{1}{ \\sqrt{2\\pi \\sigma^2}}e^{- \\frac{(x-\\mu)}{2\\sigma^2}}$$\n",
    "Чтобы получить вероятность, нужно *интегрировать* эту функцию.\n",
    "\n",
    "> Для того, чтобы понять, какие верхние и нижние границы интегрирования нужно выбрать, можно воспользоваться **правилом трех сигм** (которое было описано в части про стандартное отклонение).\n",
    "\n",
    "### Доверительный интервал\n",
    "Доверительный интервал — это нижняя и верхняя границы значений, обычно центрированных по среднему значению, описывающих диапазон высокой вероятности, как правило, 95, 99 или 99,9%\n",
    "> Когда мы говорим что-то вроде «95 %-ный доверительный интервал составляет от 12 до 20», мы имеем в виду, что существует\n",
    "95 %-ная вероятность того, что наше истинное измерение находится где-то\n",
    "между 12 и 20\n",
    "\n",
    "### Квантиль\n",
    "Квантильная функия является обратной функцией CDF. Она позволяет получить значение по заданной вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Виды графиков\n",
    "+графики для метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
